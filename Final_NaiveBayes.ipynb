{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "\"the cats nestle close to their kittens\",\n",
      "\"the lambs have laid down with the sheep\", \n",
      "\"youâ€™re cozy and warm in your bed, my dear\", \n",
      "\"please go the fuck to sleep\",\n",
      "\"the windows are dark in the town, child\",\n",
      "\"the whales huddle down in the deep\",\n",
      "\"i will read you one very last book if you swear you will go the fuck to sleep\",\n",
      "\"the eagles who soar through the sky are at rest like the creatures who crawl, run, and creep\",\n",
      "\"i know youâ€™re not thirsty\",\n",
      "\"that is bullshit\",\n",
      "\"stop lying\", \n",
      "\"lie the fuck down, my darling, and sleep\",\n",
      "\"the wind whispers soft through the grass,hon\",\n",
      "\"the field mice, they make not a peep\",\n",
      "\"it has been thirty-eight minutes already\",\n",
      "\"jesus christ, what the fuck, go to sleep\",\n",
      "\"all the nursery kids are in dreamland\",\n",
      "\"the froggie has made his last leap\",\n",
      "\"hell no, you canâ€™t go to the bathroom\",\n",
      "\"you know where you can go ,the fuck to sleep\",\n",
      "\"the owls fly forth from the treetops\",\n",
      "\"through the air, they soar and they sweep\",\n",
      "\"a hot crimson rage fills my heart, love\",\n",
      "\"come on, shut the fuck up and sleep\",\n",
      "\"the cubs and the lions are snoring, wrapped in a big snuggly heap\",\n",
      "\"how come you can do all this other great shit but you canâ€™t lie the fuck down and sleep\",\n",
      "\"the seeds slumber beneath the earth now and the crops that the farmers will reap\",\n",
      "\"no more questions\",\n",
      "\"this  interview is  over and iâ€™ve got two words for you, kid: fucking sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the giant pangolins of madagascar are snoozing as i lie here and openly weep\",\n",
      "\"who the fuck cares\",\n",
      "\"this room is all i can remember, the furniture crappy and cheap\",\n",
      "\"you win. you escape. you run down the hall. as i nod the fuck off, and sleep\",\n",
      "\"my fingers crossed tight as i tiptoe away and pray that youâ€™re fucking asleep\",\n",
      "\"weâ€™re finally watching our movie\",\n",
      "\"oh shit, goddamn it, youâ€™ve got to be kidding, come on, go the fuck back to sleep\" ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "file = open (\"data.txt\", \"r\") \n",
    "if file.mode == \"r\": \n",
    "    data = file.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck</td>\n",
       "      <td>anal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleep</td>\n",
       "      <td>analsex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>anus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mansbach</td>\n",
       "      <td>asshole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review    words\n",
       "0        go    abuse\n",
       "1      fuck     anal\n",
       "2     sleep  analsex\n",
       "3      adam     anus\n",
       "4  mansbach  asshole"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"actual_data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading subjectivity: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances = 300\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "len(subj_docs), len(obj_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_115 = df.review[:115]\n",
    "review_231 = df.review[115:231]\n",
    "words_115 = df.words[:115]\n",
    "words_231 = df.words[115:231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test_subj_docs = review_231\n",
    "##train_obj_docs = words_115\n",
    "##test_obj_docs = words_231\n",
    "##training_docs = train_subj_docs+train_obj_docs\n",
    "##testing_docs = test_subj_docs+test_obj_docs\n",
    "\n",
    "#all_words_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "training_docs = train_subj_docs+train_obj_docs\n",
    "testing_docs = test_subj_docs+test_obj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "len(unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "                                print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VADER FOR SENTIMENT ANALYSIS\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"that is bullshit\", \"stop lying\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_lexicon: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "\"the cats nestle close to their kittens\",\n",
      "\"the lambs have laid down with the sheep\", \n",
      "\"youâ€™re cozy and warm in your bed, my dear\", \n",
      "\"please go the fuck to sleep\",\n",
      "\"the windows are dark in the town, child\",\n",
      "\"the whales huddle down in the deep\",\n",
      "\"i will read you one very last book if you swear you will go the fuck to sleep\",\n",
      "\"the eagles who soar through the sky are at rest like the creatures who crawl, run, and creep\",\n",
      "\"i know youâ€™re not thirsty\",\n",
      "\"that is bullshit\",\n",
      "\"stop lying\", \n",
      "\"lie the fuck down, my darling, and sleep\",\n",
      "\"the wind whispers soft through the grass,hon\",\n",
      "\"the field mice, they make not a peep\",\n",
      "\"it has been thirty-eight minutes already\",\n",
      "\"jesus christ, what the fuck, go to sleep\",\n",
      "\"all the nursery kids are in dreamland\",\n",
      "\"the froggie has made his last leap\",\n",
      "\"hell no, you canâ€™t go to the bathroom\",\n",
      "\"you know where you can go ,the fuck to sleep\",\n",
      "\"the owls fly forth from the treetops\",\n",
      "\"through the air, they soar and they sweep\",\n",
      "\"a hot crimson rage fills my heart, love\",\n",
      "\"come on, shut the fuck up and sleep\",\n",
      "\"the cubs and the lions are snoring, wrapped in a big snuggly heap\",\n",
      "\"how come you can do all this other great shit but you canâ€™t lie the fuck down and sleep\",\n",
      "\"the seeds slumber beneath the earth now and the crops that the farmers will reap\",\n",
      "\"no more questions\",\n",
      "\"this  interview is  over and iâ€™ve got two words for you, kid: fucking sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the giant pangolins of madagascar are snoozing as i lie here and openly weep\",\n",
      "\"who the fuck cares\",\n",
      "\"this room is all i can remember, the furniture crappy and cheap\",\n",
      "\"you win. you escape. you run down the hall. as i nod the fuck off, and sleep\",\n",
      "\"my fingers crossed tight as i tiptoe away and pray that youâ€™re fucking asleep\",\n",
      "\"weâ€™re finally watching our movie\",\n",
      "\"oh shit, goddamn it, youâ€™ve got to be kidding, come on, go the fuck back to sleep\" ]\n",
      "\n",
      "\n",
      "[\n",
      "\"the cats nestle close to their kittens\",\n",
      "\"the lambs have laid down with the sheep\", \n",
      "\"youâ€™re cozy and warm in your bed, my dear\", \n",
      "\"please go the fuck to sleep\",\n",
      "\"the windows are dark in the town, child\",\n",
      "\"the whales huddle down in the deep\",\n",
      "\"i will read you one very last book if you swear you will go the fuck to sleep\",\n",
      "\"the eagles who soar through the sky are at rest like the creatures who crawl, run, and creep\",\n",
      "\"i know youâ€™re not thirsty\",\n",
      "\"that is bullshit\",\n",
      "\"stop lying\", \n",
      "\"lie the fuck down, my darling, and sleep\",\n",
      "\"the wind whispers soft through the grass,hon\",\n",
      "\"the field mice, they make not a peep\",\n",
      "\"it has been thirty-eight minutes already\",\n",
      "\"jesus christ, what the fuck, go to sleep\",\n",
      "\"all the nursery kids are in dreamland\",\n",
      "\"the froggie has made his last leap\",\n",
      "\"hell no, you canâ€™t go to the bathroom\",\n",
      "\"you know where you can go ,the fuck to sleep\",\n",
      "\"the owls fly forth from the treetops\",\n",
      "\"through the air, they soar and they sweep\",\n",
      "\"a hot crimson rage fills my heart, love\",\n",
      "\"come on, shut the fuck up and sleep\",\n",
      "\"the cubs and the lions are snoring, wrapped in a big snuggly heap\",\n",
      "\"how come you can do all this other great shit but you canâ€™t lie the fuck down and sleep\",\n",
      "\"the seeds slumber beneath the earth now and the crops that the farmers will reap\",\n",
      "\"no more questions\",\n",
      "\"this  interview is  over and iâ€™ve got two words for you, kid: fucking sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the tiger reclines in the simmering jungle\",\n",
      "\"the sparrow has silenced her cheep\",\n",
      "\"fuck your stuffed bear, iâ€™m not getting you shit\",\n",
      "\"close your eyes. cut the crap. sleep\",\n",
      "\"the giant pangolins of madagascar are snoozing as i lie here and openly weep\",\n",
      "\"who the fuck cares\",\n",
      "\"this room is all i can remember, the furniture crappy and cheap\",\n",
      "\"you win. you escape. you run down the hall. as i nod the fuck off, and sleep\",\n",
      "\"my fingers crossed tight as i tiptoe away and pray that youâ€™re fucking asleep\",\n",
      "\"weâ€™re finally watching our movie\",\n",
      "\"oh shit, goddamn it, youâ€™ve got to be kidding, come on, go the fuck back to sleep\" ]\n",
      "\n",
      "compound: -0.9961, neg: 0.18, neu: 0.773, pos: 0.047, \n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences:\n",
    "            print(data)\n",
    "    \n",
    "    \n",
    "ss = sid.polarity_scores(data)\n",
    "for k in sorted(ss):\n",
    "                    print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
